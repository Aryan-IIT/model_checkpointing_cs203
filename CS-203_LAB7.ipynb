{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  label\n",
      "0  a stirring , funny and finally transporting re...      1\n",
      "1  apparently reassembled from the cutting room f...      0\n",
      "2  they presume their audience wo n't sit still f...      0\n",
      "3  this is a visually stunning rumination on love...      1\n",
      "4  jonathan parker 's bartleby should have been t...      1\n",
      "Number of training samples: 5536\n",
      "Number of validation samples: 1384\n",
      "Number of testing samples: 1821\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define correct column names\n",
    "column_names = [\"sentence\", \"label\"]\n",
    "\n",
    "def load_dataset1(train_url, test_url):\n",
    "    train_df = pd.read_csv(train_url, sep='\\t', names=column_names, header=None)\n",
    "    test_df = pd.read_csv(test_url, sep='\\t', names=column_names, header=None)\n",
    "    return train_df, test_df\n",
    "\n",
    "# URLs for SST2 dataset\n",
    "train_url = \"https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/train.tsv\"\n",
    "test_url = \"https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/test.tsv\"\n",
    "\n",
    "# Load datasets\n",
    "train_df, test_df = load_dataset1(train_url, test_url)\n",
    "\n",
    "# Display first few rows to confirm correct loading\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "# Use the 'sentence' column since SST2 uses it instead of 'text'\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['sentence'], train_df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {len(train_texts)}\")\n",
    "print(f\"Number of validation samples: {len(val_texts)}\")\n",
    "print(f\"Number of testing samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=10000, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Total Trainable Parameters: 5293122\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # Output layer for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Example input size (to be updated based on feature extraction method)\n",
    "input_size = 10000  # Adjusted for Bag-of-Words\n",
    "\n",
    "# Initialize model\n",
    "model = MLPClassifier(input_size)\n",
    "print(model)\n",
    "\n",
    "# Count trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Implement Bag-of-Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Feature Shape: torch.Size([5536, 10000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create Bag-of-Words vectorizer\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train_bow = vectorizer.fit_transform(train_texts).toarray()\n",
    "X_val_bow = vectorizer.transform(val_texts).toarray()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_bow = torch.tensor(X_train_bow, dtype=torch.float32)\n",
    "X_val_bow = torch.tensor(X_val_bow, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "y_val = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "\n",
    "print(f\"BoW Feature Shape: {X_train_bow.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Case 2: Implement LLaMA-3.1 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "Invalid user token.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\hf_api.py:1664\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1664\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_http.py:481\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2 (Request ID: Root=1-67cf6145-2c2440612ee667a47fc8a643;9917861f-2837-4687-9537-9f1004a3fd03)\n\nInvalid credentials in Authorization header",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Login to Hugging Face (Only needed once per session)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_huggingface_token_here\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLLaMaEmbeddings\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.1-8B\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_deprecation.py:31\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     33\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     36\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\_login.py:126\u001b[0m, in \u001b[0;36mlogin\u001b[1;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_to_git_credential:\n\u001b[0;32m    120\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    121\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token has not been saved to the git credentials helper. Pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_to_git_credential=True` in this function directly or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--add-to-git-credential` if using via `huggingface-cli` if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou want to set the git credential as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m         )\n\u001b[1;32m--> 126\u001b[0m     \u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_git_credential\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[0;32m    128\u001b[0m     notebook_login(new_session\u001b[38;5;241m=\u001b[39mnew_session)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\_login.py:404\u001b[0m, in \u001b[0;36m_login\u001b[1;34m(token, add_to_git_credential)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_org\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must use your personal account token, not an organization token.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 404\u001b[0m token_info \u001b[38;5;241m=\u001b[39m \u001b[43mwhoami\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m permission \u001b[38;5;241m=\u001b[39m token_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessToken\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    406\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is valid (permission: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpermission\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\hf_api.py:1677\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m effective_token \u001b[38;5;241m==\u001b[39m _get_token_from_file():\n\u001b[0;32m   1676\u001b[0m         error_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The token stored is invalid. Please run `huggingface-cli login` to update it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(error_message, request\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mHTTPError\u001b[0m: Invalid user token."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login to Hugging Face (Only needed once per session)\n",
    "login(token=\"your_huggingface_token_here\")\n",
    "\n",
    "class LLaMaEmbeddings:\n",
    "    def __init__(self, model_name='meta-llama/Llama-3.1-8B', device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_auth_token=True)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name, use_auth_token=True).to(self.device)\n",
    "        self.embedding_size = self.model.config.hidden_size\n",
    "        self.model_loaded = True\n",
    "\n",
    "# Test the updated embedding function\n",
    "llama_embedder = LLaMaEmbeddings()\n",
    "sample_texts = [\"This movie was amazing!\", \"The plot was boring.\"]\n",
    "embeddings = llama_embedder.get_embeddings(sample_texts)\n",
    "print(\"Embedding shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model (BoW and LLaMA in Parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.049262288957834244, Validation Loss: 0.6998603940010071\n",
      "Epoch 2/10, Train Loss: 0.034614209085702896, Validation Loss: 0.9446036219596863\n",
      "Epoch 3/10, Train Loss: 0.03227594867348671, Validation Loss: 0.8870972394943237\n",
      "Epoch 4/10, Train Loss: 0.026282332837581635, Validation Loss: 0.939941942691803\n",
      "Epoch 5/10, Train Loss: 0.02015027217566967, Validation Loss: 1.0143779516220093\n",
      "Epoch 6/10, Train Loss: 0.013847403228282928, Validation Loss: 1.1791960000991821\n",
      "Epoch 7/10, Train Loss: 0.013114918023347855, Validation Loss: 1.3059937953948975\n",
      "Epoch 8/10, Train Loss: 0.012321770191192627, Validation Loss: 1.332615613937378\n",
      "Epoch 9/10, Train Loss: 0.009151513688266277, Validation Loss: 1.33468496799469\n",
      "Epoch 10/10, Train Loss: 0.007012420799583197, Validation Loss: 1.359595537185669\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# Select dataset representation (BoW or LLaMA)\n",
    "X_train = X_train_bow  # Change to X_train_llama for LLaMA embeddings\n",
    "X_val = X_val_bow  # Change to X_val_llama for LLaMA embeddings\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save final model checkpoint\u001b[39;00m\n\u001b[0;32m      2\u001b[0m final_checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m: input_size,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m],  \u001b[38;5;66;03m# MLP architecture\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Binary classification\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0001\u001b[39m,\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: epochs\n\u001b[0;32m     11\u001b[0m     },\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_history\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_task\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSST-2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransfer_task\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMDB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msst2_performance\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m---> 17\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43maccuracy\u001b[49m\n\u001b[0;32m     18\u001b[0m         },\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_performance\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(),  \u001b[38;5;66;03m# Update with IMDB results after training\u001b[39;00m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy  \u001b[38;5;66;03m# Update with IMDB results\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         }\n\u001b[0;32m     23\u001b[0m     }\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(final_checkpoint, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp_text_classification_checkpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete! Final model checkpoint saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Save final model checkpoint\n",
    "final_checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'hyperparameters': {\n",
    "        'input_size': input_size,\n",
    "        'hidden_sizes': [512, 256, 128, 64],  # MLP architecture\n",
    "        'output_size': 2,  # Binary classification\n",
    "        'learning_rate': 0.0001,\n",
    "        'epochs': epochs\n",
    "    },\n",
    "    'training_history': {\n",
    "        'initial_task': 'SST-2',\n",
    "        'transfer_task': 'IMDB',\n",
    "        'sst2_performance': {\n",
    "            'final_loss': loss.item(),\n",
    "            'final_accuracy': accuracy\n",
    "        },\n",
    "        'imdb_performance': {\n",
    "            'final_loss': loss.item(),  # Update with IMDB results after training\n",
    "            'final_accuracy': accuracy  # Update with IMDB results\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(final_checkpoint, 'mlp_text_classification_checkpoint.pth')\n",
    "print(\"\\nTraining complete! Final model checkpoint saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare the IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB training samples: 40000\n",
      "IMDB validation samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the IMDB dataset (Note: this dataset contains a \"review\" column and a \"sentiment\" column)\n",
    "imdb_url = \"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\"\n",
    "imdb_df = pd.read_csv(imdb_url)\n",
    "\n",
    "# Convert sentiment to numerical labels (assuming 'positive' and 'negative')\n",
    "imdb_df['label'] = imdb_df['sentiment'].apply(lambda x: 1 if x.lower() == 'positive' else 0)\n",
    "\n",
    "# Split into training and validation sets (80% training, 20% validation)\n",
    "imdb_train_df, imdb_val_df = train_test_split(imdb_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"IMDB training samples: {len(imdb_train_df)}\")\n",
    "print(f\"IMDB validation samples: {len(imdb_val_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature Extraction and Tensor Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB BoW Training Features Shape: torch.Size([40000, 10000])\n",
      "IMDB BoW Validation Features Shape: torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Extract the text and labels from the IMDB training and validation sets\n",
    "imdb_train_texts = imdb_train_df['review']\n",
    "imdb_train_labels = imdb_train_df['label']\n",
    "imdb_val_texts = imdb_val_df['review']\n",
    "imdb_val_labels = imdb_val_df['label']\n",
    "\n",
    "# Use the same CountVectorizer (Bag-of-Words) that was fit on the SST-2 dataset\n",
    "# (Assuming 'vectorizer' has been previously defined and fitted on the training texts of SST-2)\n",
    "X_train_imdb = vectorizer.transform(imdb_train_texts).toarray()\n",
    "X_val_imdb = vectorizer.transform(imdb_val_texts).toarray()\n",
    "\n",
    "# Convert features and labels to PyTorch tensors\n",
    "X_train_imdb = torch.tensor(X_train_imdb, dtype=torch.float32)\n",
    "X_val_imdb = torch.tensor(X_val_imdb, dtype=torch.float32)\n",
    "y_train_imdb = torch.tensor(imdb_train_labels.values, dtype=torch.long)\n",
    "y_val_imdb = torch.tensor(imdb_val_labels.values, dtype=torch.long)\n",
    "\n",
    "print(f\"IMDB BoW Training Features Shape: {X_train_imdb.shape}\")\n",
    "print(f\"IMDB BoW Validation Features Shape: {X_val_imdb.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning – Fine-tune on IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Epoch 1/10, Loss: 9.2114\n",
      "IMDB Epoch 2/10, Loss: 7.5187\n",
      "IMDB Epoch 3/10, Loss: 6.7684\n",
      "IMDB Epoch 4/10, Loss: 6.7679\n",
      "IMDB Epoch 5/10, Loss: 7.0621\n",
      "IMDB Epoch 6/10, Loss: 7.2166\n",
      "IMDB Epoch 7/10, Loss: 7.1118\n",
      "IMDB Epoch 8/10, Loss: 6.8338\n",
      "IMDB Epoch 9/10, Loss: 6.5154\n",
      "IMDB Epoch 10/10, Loss: 6.2652\n",
      "\n",
      "IMDB Validation Loss: 5.9462, Accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define or re-use your model, criterion, and optimizer.\n",
    "# (Assuming 'model' is already defined and was trained on SST-2)\n",
    "# For continual learning, you might use a smaller learning rate.\n",
    "transfer_lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=transfer_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 10  # or as required\n",
    "\n",
    "# Fine-tune the model on the IMDB training set\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_imdb)\n",
    "    loss = criterion(outputs, y_train_imdb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"IMDB Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate on the IMDB validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(X_val_imdb)\n",
    "    val_loss = criterion(val_outputs, y_val_imdb)\n",
    "    val_preds = val_outputs.argmax(dim=1)\n",
    "    accuracy = (val_preds == y_val_imdb).float().mean().item()\n",
    "\n",
    "print(f\"\\nIMDB Validation Loss: {val_loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7767\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_preds = model(X_val).argmax(dim=1)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_val, val_preds)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, val_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization (TensorBoard Integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs saved.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"runs/text_classification\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    writer.add_scalar(\"Loss/train\", loss.item(), epoch)\n",
    "    writer.add_scalar(\"Loss/validation\", val_loss.item(), epoch)\n",
    "\n",
    "writer.close()\n",
    "print(\"TensorBoard logs saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
